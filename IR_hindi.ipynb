{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfw3LED9Xu1D",
    "outputId": "bfd36aeb-403d-47d7-e309-f8efb85f9b89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OFuyAcyVZjq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "!pip install transformers\n",
    "\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1t1tQnpSwGV"
   },
   "outputs": [],
   "source": [
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0oh7BZ6nROCh"
   },
   "outputs": [],
   "source": [
    "def dataAnalyzer(targets, outputs):\n",
    "  label_dict = {'offensive': 0, 'fake': 1, 'defamation': 2, 'hate': 3, 'non-hostile': 4}\n",
    "  predCounts = [0, 0, 0, 0, 0]\n",
    "  realCounts = [0, 0, 0, 0, 0]\n",
    "  inpredCounts = [0, 0, 0, 0, 0]\n",
    "  inrealCounts = [0, 0, 0, 0, 0]\n",
    "\n",
    "  for i in range(len(targets)):\n",
    "    for j in range(len(label_dict)):\n",
    "      if targets[i][j] == 1:\n",
    "        realCounts[j] += 1\n",
    "        if targets[i][j] == outputs[i][j]:\n",
    "          predCounts[j] += 1\n",
    "      else:\n",
    "        inrealCounts[j] += 1\n",
    "        if targets[i][j] == outputs[i][j]:\n",
    "          inpredCounts[j] += 1\n",
    "\n",
    "  print(\"True +ve\")\n",
    "  print(predCounts)\n",
    "  print(\"Total +ve\")\n",
    "  print(realCounts)\n",
    "  print(\"True -ve\")\n",
    "  print(inpredCounts)\n",
    "  print(\"Total -ve\")\n",
    "  print(inrealCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HEpvQAVDQhR9"
   },
   "outputs": [],
   "source": [
    "def multi_hot_encoder(labels):\n",
    "  label_array = [label.split(',') for label in labels]\n",
    "  label_dict = {'offensive': 0, 'fake': 1, 'defamation': 2, 'hate': 3, 'non-hostile': 4}\n",
    "  labels = np.zeros(shape=(len(label_array), len(label_dict)))\n",
    "  for i, label in enumerate(label_array):\n",
    "    for l in label:\n",
    "      labels[i][(label_dict[l])] = 1\n",
    "  \n",
    "  return labels\n",
    "\n",
    "\n",
    "def binary_encoder(labels):\n",
    "  label_array = [label.split(',') for label in labels]\n",
    "  label_dict = {'offensive': 0, 'fake': 1, 'defamation': 2, 'hate': 3, 'non-hostile': 4}\n",
    "  labels = np.zeros(shape=len(label_array), dtype=np.int32)\n",
    "  for i, label in enumerate(label_array):\n",
    "    if label_dict[label[0]] < 4:\n",
    "      labels[i] = 1\n",
    "\n",
    "  return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "9d1ae0a0cb5b4f72adf6fe2d0b350473",
      "3a1989be8e3d42a49de5afa3dc31a53e",
      "e8254865a508403197e503862b2b0267",
      "53f77f4a519d4587b5e2655832f0a3ce",
      "a793993eeee94f648876a6569271d68f",
      "06497f4d356a47468e2700bae89c0fcf",
      "aaab015e997048efa9a2059a3157086a",
      "449fc797f70c4bbabeb4a3f9a0d6b861"
     ]
    },
    "id": "T5uPwBLBasuq",
    "outputId": "8938f62b-bbf0-48a7-a2ae-7c252f9a1d01"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1ae0a0cb5b4f72adf6fe2d0b350473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=871891.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 5\n",
    "BERT_PATH = \"bert-base-multilingual-uncased\"\n",
    "MODEL_PATH = \"/content/drive//My Drive/IR_Hindi/Models_Multi/model9.bin\"\n",
    "MODEL_PATH_BINARY = \"/content/drive//My Drive/IR_Hindi/Models_Binary/model3.bin\"\n",
    "TRAINING_FILE = \"/content/drive//My Drive/IR_Hindi/train.csv\"\n",
    "VALIDATION_FILE = \"/content/drive//My Drive/IR_Hindi/Constraint_Hindi_Valid - Sheet1.csv\"\n",
    "TEST_FILE = \"/content/drive//My Drive/IR_Hindi/Test Set - test.csv\"\n",
    "FILE_SAVE_PATH = \"/content/drive//My Drive/IR_Hindi/Quark_test_1.csv\"\n",
    "TOKENIZER = transformers.BertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "I1ugnW0iWqd5"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, review, target):\n",
    "        self.review = review\n",
    "        self.target = target\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.max_len = MAX_LEN\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.review[item])\n",
    "        review = \" \".join(review.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"targets\": torch.tensor(self.target[item], dtype=torch.float),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NcunjDpIeEcO"
   },
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "        self.bert = transformers.BertModel.from_pretrained(BERT_PATH)\n",
    "        self.bert_drop = nn.Dropout(0.2)\n",
    "        self.lin1 = nn.Linear(768, 256)\n",
    "        self.lin2 = nn.Linear(256, 5)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        o = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        bo = self.bert_drop(o.pooler_output)\n",
    "        output = nn.functional.relu(self.lin1(bo))\n",
    "        output = self.lin2(output)\n",
    "        return output\n",
    "\n",
    "class BERT_Binary(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT_Binary, self).__init__()\n",
    "        self.bert = transformers.BertModel.from_pretrained(BERT_PATH)\n",
    "        self.bert_drop = nn.Dropout(0.2)\n",
    "        self.lin1 = nn.Linear(768, 256)\n",
    "        self.lin2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        o = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        bo = self.bert_drop(o.pooler_output)\n",
    "        output = nn.functional.relu(self.lin1(bo))\n",
    "        output = self.lin2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_i_16DZMdjV2"
   },
   "outputs": [],
   "source": [
    "# Change loss function for multi-label\n",
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "def loss_fn_binary(outputs, targets):\n",
    "  return nn.BCEWithLogitsLoss()(outputs, targets.view(-1,1))\n",
    "\n",
    "\n",
    "def train_fn(data_loader, model, optimizer, device, scheduler, isBinary):\n",
    "    model.train()\n",
    "\n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets = d[\"targets\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
    "        if isBinary:\n",
    "          loss = loss_fn_binary(outputs, targets)\n",
    "        else:\n",
    "          loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pFjUNEZ4gKs1"
   },
   "outputs": [],
   "source": [
    "def sentence_prediction(MODEL, sentence):\n",
    "    tokenizer = TOKENIZER\n",
    "    max_len = MAX_LEN\n",
    "    review = str(sentence)\n",
    "    review = \" \".join(review.split())\n",
    "\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        review, None, add_special_tokens=True, max_length=max_len, truncation=True,\n",
    "    )\n",
    "\n",
    "    ids = inputs[\"input_ids\"]\n",
    "    mask = inputs[\"attention_mask\"]\n",
    "    token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "    padding_length = max_len - len(ids)\n",
    "    ids = ids + ([0] * padding_length)\n",
    "    mask = mask + ([0] * padding_length)\n",
    "    token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "\n",
    "    ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n",
    "    mask = torch.tensor(mask, dtype=torch.long).unsqueeze(0)\n",
    "    token_type_ids = torch.tensor(token_type_ids, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    ids = ids.to(DEVICE, dtype=torch.long)\n",
    "    token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n",
    "    mask = mask.to(DEVICE, dtype=torch.long)\n",
    "\n",
    "    outputs = MODEL(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
    "\n",
    "    outputs = torch.sigmoid(outputs).cpu().detach().numpy()\n",
    "    return outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AM9V9erOVNMW"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "def run(binaryClassification=False):\n",
    "    df_train = pd.read_csv(TRAINING_FILE)\n",
    "    df_valid = pd.read_csv(VALIDATION_FILE)\n",
    "    \n",
    "    # Url Removal\n",
    "    for i,v in enumerate(df_train['Post']):\n",
    "      if type(v)==float:\n",
    "        break\n",
    "      v = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', ' ', v, flags=re.MULTILINE)\n",
    "      df_train.loc[i,'Post'] = v\n",
    "\n",
    "    for i,v in enumerate(df_valid['Post']):\n",
    "      if type(v)==float:\n",
    "        break\n",
    "      v = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', ' ', v, flags=re.MULTILINE)\n",
    "      df_valid.loc[i,'Post'] = v\n",
    "\n",
    "    if binaryClassification:\n",
    "      train_targets = binary_encoder(df_train['Labels Set'])\n",
    "      valid_targets = binary_encoder(df_valid['Labels Set'])\n",
    "    else:\n",
    "      train_targets = multi_hot_encoder(df_train['Labels Set'])\n",
    "      valid_targets = multi_hot_encoder(df_valid['Labels Set'])\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_valid = df_valid.reset_index(drop=True)\n",
    "\n",
    "    train_dataset = Dataset(review=df_train['Post'], target=train_targets)\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, num_workers=4)\n",
    "    valid_dataset = Dataset(review=df_valid['Post'], target=valid_targets)\n",
    "    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=VALID_BATCH_SIZE, num_workers=1)\n",
    "\n",
    "    device = torch.device(DEVICE)\n",
    "    model = BERT_Binary() if binaryClassification else BERT()\n",
    "    model.to(device)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.001,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=3e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "    best_f1_score = 0\n",
    "    save_path = MODEL_PATH_BINARY if binaryClassification else MODEL_PATH\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler, binaryClassification)\n",
    "        outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "        outputs = np.array(outputs) >= 0.5\n",
    "        targets = np.array(targets)\n",
    "        f1_score = metrics.f1_score(targets[:,:4], outputs[:,:4], average=\"weighted\")\n",
    "        print(f\"F1 Score = {f1_score}\")\n",
    "        if f1_score > best_f1_score:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            best_f1_score = f1_score\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iHy5oG177P6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "MODEL = BERT()\n",
    "MODEL.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(DEVICE)))\n",
    "MODEL.to(DEVICE)\n",
    "MODEL.eval()\n",
    "\n",
    "# Just for reference\n",
    "# label_dict = {'offensive': 0, 'fake': 1, 'defamation': 2, 'hate': 3, 'non-hostile': 4}\n",
    "\n",
    "df_valid = pd.read_csv(VALIDATION_FILE)\n",
    "valid_targets = multi_hot_encoder(df_valid['Labels Set'])\n",
    "valid_dataset = Dataset(review=df_valid['Post'], target=valid_targets)\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset, batch_size=VALID_BATCH_SIZE, num_workers=1\n",
    ")\n",
    "outputs, targets = eval_fn(valid_data_loader, MODEL, DEVICE)\n",
    "preds = np.array(outputs) >= 0.5\n",
    "f1 = metrics.f1_score(targets, preds, average=\"weighted\")\n",
    "print(f\"F1 Score = {f1}\")\n",
    "\n",
    "dataAnalyzer(targets, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSddpBhrfZ24"
   },
   "outputs": [],
   "source": [
    "f1 = metrics.f1_score(np.array(targets)[:,:4], np.array(preds)[:,:4], average=\"weighted\")\n",
    "print(f\"F1 Score = {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8CXDZ0bWs18"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "MODEL = BERT()\n",
    "binary = BERT_Binary()\n",
    "MODEL.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(DEVICE)))\n",
    "binary.load_state_dict(torch.load(MODEL_PATH_BINARY, map_location=torch.device(DEVICE)))\n",
    "MODEL.to(DEVICE)\n",
    "binary.to(DEVICE)\n",
    "MODEL.eval()\n",
    "binary.eval()\n",
    "\n",
    "df_test = pd.read_csv(TEST_FILE)\n",
    "\n",
    "test_data = df_test['Post']\n",
    "\n",
    "for i,v in enumerate(df_train['Post']):\n",
    "      if type(v)==float:\n",
    "        break\n",
    "      v = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', ' ', v, flags=re.MULTILINE)\n",
    "      df_test.loc[i,'Post'] = v\n",
    "\n",
    "preds = []\n",
    "binary_preds = []\n",
    "for post in test_data:\n",
    "  pred = sentence_prediction(MODEL, post)\n",
    "  binary_pred = sentence_prediction(binary, post)[0]\n",
    "  preds.append(pred)\n",
    "  binary_preds.append(binary_pred)\n",
    "\n",
    "\n",
    "preds = np.array(preds) >= 0.5\n",
    "binary_preds = np.array(binary_preds) >= 0.5\n",
    "outs = []\n",
    "label_dict = {0: 'offensive', 1: 'fake', 2: 'defamation', 3: 'hate', 4: 'non-hostile'}\n",
    "for pred, binary_pred in zip(preds, binary_preds):\n",
    "  s = \"\"\n",
    "  if binary_pred == 0:\n",
    "    s = \"non-hostile, \"\n",
    "  else:\n",
    "    for j, val in enumerate(pred):\n",
    "      if val == 1:\n",
    "        s += (label_dict[j] + ', ')\n",
    "  outs.append(s[:-2])\n",
    "\n",
    "to_save = list(zip(range(1,len(outs)+1), outs))\n",
    "df = pd.DataFrame(to_save,\n",
    "               columns =['Unique ID', 'Labels Set'])\n",
    "df.to_csv(FILE_SAVE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eflhpx-GIaVi",
    "outputId": "80bb8114-f40b-4c4e-8eca-657e7c5aad1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.9963337988826816\n",
      "Hostile Count:  2678\n",
      "Correct Hostile:  2675\n",
      "Non-hostile Count:  3050\n",
      "Correct Non-hostile:  3032\n"
     ]
    }
   ],
   "source": [
    "hCount, nhCount = 0, 0\n",
    "cH, incH = 0, 0\n",
    "for i in range(len(targets)):\n",
    "  if targets[i] == 1:\n",
    "    hCount += 1\n",
    "    if targets[i] == outputs[i]:\n",
    "      cH += 1\n",
    "  else:\n",
    "    nhCount += 1\n",
    "    if targets[i] == outputs[i]:\n",
    "      incH += 1\n",
    "\n",
    "print(\"Hostile Count: \", hCount)\n",
    "print(\"Correct Hostile: \", cH)\n",
    "print(\"Non-hostile Count: \", nhCount)\n",
    "print(\"Correct Non-hostile: \", incH)\n",
    "# accuracy = metrics.accuracy_score(targets, outputs)\n",
    "# print(f\"Accuracy Score = {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IR-hindi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06497f4d356a47468e2700bae89c0fcf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a1989be8e3d42a49de5afa3dc31a53e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "449fc797f70c4bbabeb4a3f9a0d6b861": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53f77f4a519d4587b5e2655832f0a3ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_449fc797f70c4bbabeb4a3f9a0d6b861",
      "placeholder": "​",
      "style": "IPY_MODEL_aaab015e997048efa9a2059a3157086a",
      "value": " 872k/872k [00:00&lt;00:00, 6.27MB/s]"
     }
    },
    "9d1ae0a0cb5b4f72adf6fe2d0b350473": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e8254865a508403197e503862b2b0267",
       "IPY_MODEL_53f77f4a519d4587b5e2655832f0a3ce"
      ],
      "layout": "IPY_MODEL_3a1989be8e3d42a49de5afa3dc31a53e"
     }
    },
    "a793993eeee94f648876a6569271d68f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "aaab015e997048efa9a2059a3157086a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8254865a508403197e503862b2b0267": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06497f4d356a47468e2700bae89c0fcf",
      "max": 871891,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a793993eeee94f648876a6569271d68f",
      "value": 871891
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
